{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f2e5d2-3054-4578-b911-2610cc9696e1",
   "metadata": {},
   "source": [
    "# Float16 vs Float32 Speed Considerations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a14bfc-34ad-4069-9f7f-661d352feaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b3cad-6490-4058-893b-05f76016dd19",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to examine times for reading and writing hd5 files as full float32, truncated precision float 32, and short floats. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd835974-4e13-4c42-bed2-c9c4c16a4259",
   "metadata": {},
   "source": [
    "# Generate Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593180e5-837d-4c9d-822e-a05be3a4fcde",
   "metadata": {},
   "source": [
    " Generate some nonsense data as combination of white noise and longer wavelength patterns. Generate truncated data with 4 signficant figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03a3b95f-3438-4cc6-aba7-75b45c6caf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to short 94.146 ms\n"
     ]
    }
   ],
   "source": [
    "nr, nc = 5000, 5000\n",
    "size = (nr, nc)\n",
    "x = np.arange(0, nc)\n",
    "y = np.arange(0, nr)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "image = 20*np.sin(X/60) + 20*np.sin(Y/200)\n",
    "image[0:int(nc*.2),:] = 0  # zero out some to simulate padding in geocoded image.\n",
    "myData = np.random.normal(loc=0, scale=20., size=size).astype(np.float32) + image.astype(np.float32)\n",
    "start = datetime.now()\n",
    "myDataShort = myData.astype(np.float16)\n",
    "dt = datetime.now() - start\n",
    "dtmsShort = float(dt.seconds) * 1000 + dt.microseconds / 1000\n",
    "print(f'Time to short {dtmsShort} ms')\n",
    "# Crude way to truncate, but serves its purpose\n",
    "myDataTrunc = np.array([np.float32(np.format_float_positional(x, precision=4, fractional=False)) for x in myData.flatten()]).reshape(size)\n",
    "dataSets = {'Float32': myData, 'Truncated': myDataTrunc, 'Float16': myDataShort}\n",
    "#plt.imshow(myData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd8703-8ccb-40d2-9cd8-dfca429bc7a8",
   "metadata": {},
   "source": [
    "Functions to read and write the data to an HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409cd009-eb83-4c22-b8b0-78ed77194538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeHDF(data, filename, compression=None):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    hf = h5py.File(filename, 'w')\n",
    "    hf.create_dataset('test', data=data, compression=compression)\n",
    "    hf.close()\n",
    "    \n",
    "def readHDF(filename):\n",
    "    f = h5py.File(filename, 'r')\n",
    "    a = np.array(f['test']).astype(np.float32)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b54448-bc73-4c80-8cb6-7d1f2f2d9fbe",
   "metadata": {},
   "source": [
    "## Write Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98caf24-29db-47ab-a61d-d9b84554d70a",
   "metadata": {},
   "source": [
    "Write the precomputed data sets to disk. This does not include the overhead of truncating precision or converting to float16 (~90ms in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbad9091-91ac-45e3-a9d6-085f00476945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet    Float32, compression       None, write time 209.0 ms, fileSize 100.00 MB\n",
      "DataSet    Float32, compression      gzip4, write time 3515.8 ms, fileSize 92.17 MB\n",
      "DataSet  Truncated, compression       None, write time 191.1 ms, fileSize 100.00 MB\n",
      "DataSet  Truncated, compression      gzip4, write time 3193.0 ms, fileSize 74.40 MB\n",
      "DataSet    Float16, compression       None, write time 102.8 ms, fileSize 50.00 MB\n",
      "DataSet    Float16, compression      gzip4, write time 1536.3 ms, fileSize 45.49 MB\n"
     ]
    }
   ],
   "source": [
    "compressionLevel = 4\n",
    "compressions = {'None': None, f'gzip{compressionLevel}': compressionLevel}\n",
    "for dataSet in dataSets:\n",
    "    for compression in compressions:\n",
    "        start = datetime.now()\n",
    "        filename =  f'{dataSet}.{compression}.h5'   \n",
    "        writeHDF(dataSets[dataSet], filename, compression=compressions[compression])\n",
    "        dt = datetime.now() - start\n",
    "        dtms = float(dt.seconds) * 1000 + dt.microseconds / 1000.\n",
    "        fileSize = os.path.getsize(filename)\n",
    "        print(f'DataSet {dataSet:>10}, compression {compression:>10}, write time {dtms:5.1f} ms, fileSize {fileSize/1e6:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94b57b-0556-4631-b210-d956578a2609",
   "metadata": {},
   "source": [
    "Now read back. Note the data are converted back to float 32, so times are directly comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37756f30-7528-478e-bf55-cc02b4c59c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSet    Float32, compression       None, read time 142.8 ms, fileSize 100.00 MB, error 0.00000\n",
      "DataSet    Float32, compression      gzip4, read time 579.2 ms, fileSize 92.17 MB, error 0.00000\n",
      "DataSet  Truncated, compression       None, read time 141.6 ms, fileSize 100.00 MB, error 0.00245\n",
      "DataSet  Truncated, compression      gzip4, read time 821.1 ms, fileSize 74.40 MB, error 0.00245\n",
      "DataSet    Float16, compression       None, read time 117.4 ms, fileSize 50.00 MB, error 0.00555\n",
      "DataSet    Float16, compression      gzip4, read time 396.5 ms, fileSize 45.49 MB, error 0.00555\n"
     ]
    }
   ],
   "source": [
    "for dataSet in dataSets:\n",
    "    for compression in compressions:\n",
    "        filename =  f'{dataSet}.{compression}.h5'\n",
    "        start = datetime.now()\n",
    "        data = readHDF(filename)\n",
    "        dt = datetime.now() - start\n",
    "        dtms = float(dt.seconds) * 1000 + dt.microseconds / 1000.\n",
    "        fileSize = os.path.getsize(filename)\n",
    "        print(f'DataSet {dataSet:>10}, compression {compression:>10}, read time {dtms:5.1f} ms, fileSize {fileSize/1e6:.2f} MB, error {np.std(dataSets[\"Float32\"]-data):.5f}')\n",
    "        if os.path.exists(filename):\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54a4e9-d883-4094-af59-4fdbd3313594",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8826c5b-05bd-4bc5-9d7f-cd3b0e38f62f",
   "metadata": {},
   "source": [
    "The following conclusions can be drawn:\n",
    "- The conversion to float16 is about ~100 ms.\n",
    "- For a not fast disk, conversion time is mostly made up on faster write.\n",
    "- Compression slows read/write considerably in all cases.\n",
    "- Truncation to 4 digits buys some space savings, but only about half has much as float16. Compression doesn't buy much otherwise (could be more with more background).\n",
    "\n",
    "The bottom line is short floats seem to work well and add no substantial overhead due to conversion and in some cases save time on i/o.\n",
    "\n",
    "Intel processors have support for the conversion since 2013. If performance is slow on other systems it could be because the compiler is not using the special instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7fe6e-3c96-4b18-b89c-71b4b418702f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
